{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVKa9zcWdm-p"
      },
      "source": [
        "# 3.1 Градиентный спуск\n",
        "\n",
        "В этом задании нам предстоит реализовать классический алгоритм градиентного спуска для обучения модели логистической регрессии.\n",
        "\n",
        "Алгоритм выполнения этого задания следующий:\n",
        "\n",
        "* На основе посчитанных в первом задании частных производных, напишем функцию подсчета градиента бинарной кросс-энтропии по параметрам модели\n",
        "\n",
        "* Напишем функцию обновления весов по посчитанным градиентам\n",
        "\n",
        "* Напишем функцию тренировки модели\n",
        "\n",
        "Замечание:\n",
        "Тренировка модели проводится в несколько циклов, в рамках каждого из которых мы обновим веса модели, основываясь на предсказании для **каждого** объекта из датасета. Такие циклы называются *эпохами*. То есть одна эпоха - это набор обновлений весов, реализованный согласно посчитанным для каждого объекта из датасета ошибкам модели.\n",
        "\n",
        "Вам необходимо реализовать обучение модели в несколько эпох. Их количество задается параметром функции. В рамках каждой эпохи необходимо пройти циклом по всем объектам обучающей выборки и обновить веса модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrTqdyBid_G8"
      },
      "source": [
        "Шаблон кода для заполнения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "CCM4EIh_d8-n"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "# Функция подсчета градиента\n",
        "def gradient(y_true: int, y_pred: float, x: np.array) -> np.array:\n",
        "    \"\"\"\n",
        "    y_true - истинное значение ответа для объекта x\n",
        "    y_pred - значение степени принадлежности объекта x классу 1, предсказанное нашей моделью\n",
        "    x - вектор признакового описания данного объекта\n",
        "\n",
        "    На выходе ожидается получить вектор частных производных H по параметрам модели, предсказавшей значение y_pred\n",
        "    Обратите внимание, что размерность этого градиента должна получиться на единицу больше размерности x засчет своободного коэффициента a0\n",
        "    \"\"\"\n",
        "    er = (1 - y_true) * y_pred - (1 - y_pred) * y_true\n",
        "    grad = er*x\n",
        "    grad = np.append(grad, er)\n",
        "    return grad\n",
        "\n",
        "\n",
        "# Функция обновления весов\n",
        "def update(alpha: np.array, gradient: np.array, lr: float):\n",
        "    \"\"\"\n",
        "    alpha: текущее приближения вектора параметров модели\n",
        "    gradient: посчитанный градиент по параметрам модели\n",
        "    lr: learning rate, множитель перед градиентом в формуле обновления параметров\n",
        "    \"\"\"\n",
        "    alpha_new = alpha - lr*gradient\n",
        "    return alpha_new\n",
        "\n",
        "def sigmoid(z: float) -> float:\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# функция тренировки модели\n",
        "def train(\n",
        "    alpha0: np.array, x_train: np.array, y_train: np.array, lr: float, num_epoch: int\n",
        "):\n",
        "    \"\"\"\n",
        "    alpha0 - начальное приближение параметров модели\n",
        "    x_train - матрица объект-признак обучающей выборки\n",
        "    y_train - верные ответы для обучающей выборки\n",
        "    lr - learning rate, множитель перед градиентом в формуле обновления параметров\n",
        "    num_epoch - количество эпох обучения, то есть полных 'проходов' через весь датасет\n",
        "    \"\"\"\n",
        "    alpha = alpha0.copy()\n",
        "    for epo in range(num_epoch):\n",
        "        for i, x in enumerate(x_train):\n",
        "            y_pred = sigmoid(np.append(x, 1) @ alpha)\n",
        "            grad = gradient(y_train[i], y_pred, x)\n",
        "            alpha = update(alpha, grad, lr)\n",
        "    return alpha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDcPxeLueFIk"
      },
      "source": [
        "# Замечания:\n",
        "\n",
        "1. В случае, если у Вас возникли сложности с выполнением первого задания и, как следствие, у Вас не выходит сделать это, мы рекомендуем подробно ознакомиться с главой **Производные $\\frac{\\partial H}{\\partial \\omega_i}$** нашей [лекции](https://colab.research.google.com/drive/1xjX_YnXcRr8HSiYLByMHxEIAADqs7QES?usp=sharing).\n",
        "\n",
        "2. Обращайте внимание на названия и порядок аргументов в сдаваемых на проверку функциях - они должны совпадать с тем, что указано в шаблоне кода.\n",
        "\n",
        "3. Обратите внимание, что матрица объект-признак в описании параметров функций обозначает переменную типа numpy.array(), каждый элемент которой - объект типа numpy.array() - вектор признаков соответствующего объекта.\n",
        "\n",
        "4. Считайте, что свободный коэффициент a0 находится **в конце** списка alpha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k= [1 2 3 1] <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "k = gradient(0, 1, np.array([1, 2, 3]))\n",
        "print(\"k=\", k, type(k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.22748798 1.15054523 0.37803321]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "    alpha0 - начальное приближение параметров модели\n",
        "    x_train - матрица объект-признак обучающей выборки\n",
        "    y_train - верные ответы для обучающей выборки\n",
        "    lr - learning rate, множитель перед градиентом в формуле обновления параметров\n",
        "    num_epoch - количество эпох обучения, то есть полных 'проходов' через весь датасет\n",
        "\"\"\"\n",
        "alpha0 = np.array([1, 1, 1])\n",
        "x_train = np.array([[0, 1], [1, 0]])\n",
        "y_train = np.array([1, 0])\n",
        "res = train(alpha0, x_train, y_train, 0.01, 100)\n",
        "print(res)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "data_analysis",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
